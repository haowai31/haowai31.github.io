<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RSS - Thinking and Recording</title>
    <description>Thinking and Recording - </description>
    <link>http://haowai31.github.io/</link>
    <atom:link href="http://haowai31.github.io//page/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 20 May 2015 16:57:12 +0800</pubDate>
    <lastBuildDate>Wed, 20 May 2015 16:57:12 +0800</lastBuildDate>
    <generator>haowai31</generator>
    
      <item>
        <title>NG机器学习的编程实验</title>
        <description>&lt;p&gt;&lt;a href=&quot;#ex1&quot;&gt;实验一：线性回归&lt;/a&gt;
&lt;a href=&quot;#ex2&quot;&gt;实验二：逻辑回归&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;今天把NG的机器学习公开课的作业又顺了一边，很多语句不用就忘了，另外矩阵运算用起来就是让人&lt;em&gt;心旷神怡&lt;/em&gt;。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;a name=&quot;ex1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;programming-assignment-linear-regression&quot;&gt;实验一，Programming Assignment: Linear Regression&lt;/h2&gt;

&lt;p&gt;这个实验就是用来熟悉一下提交的环境，另外在学习算法的各个过程都需要填几行关键程序，包括怎么求估价函数，怎么施行阶梯算法，怎么标准化数据等等，选做实验是两种特征的训练数据。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;1.1 单位矩阵&lt;/h3&gt;
&lt;p&gt;就是通过eye函数得一个单位矩阵。&lt;/p&gt;

&lt;h3 id=&quot;j&quot;&gt;1.2 计算估价函数J&lt;/h3&gt;
&lt;p&gt;（对不起我还不会写公式，回来更新）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;J = sum((X * theta - y).^2) / (2*m);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意其中的.^，这是矩阵特有的操作符号，是矩阵的每一个对应的位置进行相应的运算。sum函数则是对矩阵求和。如果得出的结果是32.07就说明程序写的没问题，总之矩阵运算一定要注意的是x*y对应起来，否则如果出错还容易发现矩阵运算没有写错，如果恰好没有提示错误，得出的结果不对这种Bug会改的头破血流。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;1.3 实现阶梯下降算法&lt;/h3&gt;
&lt;p&gt;（公式仍然不会写）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;theta(1) = theta(1) - alpha/m*sum(X*theta_backup-y);
theta(2) = theta(2) - alpha/m*sum((X*theta_backup-y).*X(:,2));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这只是单纯照着阶梯下降算法更新theta就好。值得注意的地方在上课的时候NG也说了，因为再更新theta的过程中会改变theta，所以我这里用了一个 ** theta_backup ** 对原来的theta进行了备份。这是一个特征的情况，下面还会有多种特征的简便写法（我第一次写的是循环^o^）。&lt;/p&gt;

&lt;p&gt;这个实验做到这里其实已差不多了，看到最后画出的图还是很开心的，虽然感觉上跟我并没有什么关系。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;1.4 多类特征的附加实验&lt;/h3&gt;
&lt;p&gt;具体步骤跟单类特征差不多，值得注意的就是上文提到的更新theta的简便写法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;theta = theta - alpha / m * X' * (X * theta - y); 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;X’是求X的转置矩阵。&lt;/p&gt;

&lt;p&gt;这是对数据标准化的语句，话说在pdf中间直接告诉要怎么做这样真的好嘛？连需要用的函数都给了。。。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mu = mean(X);
sigma = std(X);
X_norm = (X - repmat(mu, size(X,1) , 1))  ./ repmat(sigma,size(X,1),1);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mean()函数是求平均值，具体自己做做实验就知道了，我就是一边儿一边儿在shell上面测试函数的用法，实用是学习最快的方法。std()函数是求标准差，然后完全按照pdf的描述就可以写下这条语句了（当然，我这么笨的人在shell上面测试了好久。。）。&lt;/p&gt;

&lt;p&gt;另外视频中也提到过，如果数据规模小的话，可以直接使用矩阵进行计算：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;theta = pinv(X'*X)*X'*y;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pinv()函数是求矩阵的逆，其实就是这个函数限制着这种干脆利索的方法的运行速度的。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;1.5 总结&lt;/h3&gt;
&lt;p&gt;总之，第一次实验叫做 &lt;strong&gt;worm exercises&lt;/strong&gt; 也是有一定道理的。其实就是给 &lt;strong&gt;纸上得来&lt;/strong&gt; 和 &lt;strong&gt;恭行&lt;/strong&gt; 两件事建立个联系，知道这些算法是可以实现并且实际工作的，这对于我这样的笨蛋还是很重要的，学的时候总觉得隔层纱，到真的程序运行结果砸在脸上了，就能迷糊回来了。&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;ex2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;logistic-regression&quot;&gt;实验二，Logistic Regression&lt;/h2&gt;

&lt;p&gt;该实验总共包含两个小实验，一个是基础的逻辑回归实验，另一个是情况稍微复杂一点的实验，需要拟合的数据不是直线，当然其实如果没想那么多，跟着pdf做的话，几乎感觉不到区别，除了最后可视化的图不太一样。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;2.1 将数据可视化&lt;/h3&gt;

&lt;p&gt;可以看到，边界线大概是条直线。&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;2.2 实现&lt;/h3&gt;

&lt;p&gt;经过前面的实验熏陶，已经知道这个实验实现部分肯定包括CostFunction，下降率，自己对数据进行预测等等，所有需要做的就是照着公式用octave实现出来就可，再次强调 &lt;strong&gt;矩阵的行和列&lt;/strong&gt; 是验算式子写的对不对的有效的方法。
sigmoid函数很简单，不过注意的是这个函数接受的参数z，是矩阵，所以使用操作符号的时候一定要注意，该用“./”就要用。
求J的CostFunction，解析起来比较复杂，还是惯例，从里到外解析，注意运算符左右的矩阵的行和列，一般不会有什么问题，具体公式如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;J = 1 / m * sum((-y).*log(sigmoid(X*theta)) - (1-y).*log(1-sigmoid(X*theta)));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要注意的还是诸如“.*”这些操作符号。
而相关的gradient更新的公式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grad = 1 / m * (X' * (sigmoid(X*theta) - y));
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;
&lt;p&gt;其实costfunction写完之后，需要修改的文件已经差不多没了，但是任务并没有结束，有了costfunction要如何更新theta呢？
这里是使用了octave里面提供的fminunc函数，通过这个函数算出对于CostFunction来说最优的参数。使用方式如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;options = optimset('GradObj', 'on', 'MaxIter', 400);
[theta, cost] = fminunc(@(t)(costFunction(t, X, y)), initial_theta, options);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GradObj参数告诉fminunc使用gradient来计算需要返回theta和cost两个值，设置MaxIter最大步数为400。后面@(t)的写法是内部调用函数，同时提供theta和上文提到的options就可以等待fminunc算出结果了。并不用自己制定下降率之类的参数，大部分工作都由fminunc做了。&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;2.3 评估结果&lt;/h3&gt;

&lt;p&gt;这里就是将已经得到的theta带进h函数就好，然后把所有的值在0.5以上的数据挑出来，将其y置1就好，使用find，很容易达到目的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tmp = sigmoid(X*theta);
finde = find(tmp&amp;gt;=0.5);
p(finde,1) = 1;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以看到结果啦。&lt;/p&gt;

&lt;h3 id=&quot;regularized-logistic-regression&quot;&gt;2.4 第二个实验：Regularized logistic regression&lt;/h3&gt;

&lt;p&gt;整个流程和第一个实验差不多，需要注意的是costFunction中计算J函数和gradient更新，对于j=0和j&amp;gt;0是不一样的处理方式，另外在mapFeature函数中，使用了6次的多项式对数据进行拟合，可以看其拟合的手法，值得学习。
最后还给出了过度拟合与拟合度不够的边界值的图，可以看看。&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;2.5 总结&lt;/h3&gt;

&lt;p&gt;整体来说，大部分程序不需要自己动手，只是部分函数自己填一下就可以了，像填空一样，但是做到现在，应该慢慢对整个体系有一些印象，回来是需要自己把整个过程都写出来的，提前做准备。&lt;/p&gt;

&lt;p&gt;实验一更新（2015.05.14 21：28）
实验二更新（2015.05.20 09：50）&lt;/p&gt;
</description>
        <pubDate>Thu, 14 May 2015 00:00:00 +0800</pubDate>
        <link>http://haowai31.github.io//blog/2015/05/14/ng_ex.html</link>
        <guid isPermaLink="true">http://haowai31.github.io//blog/2015/05/14/ng_ex.html</guid>
        
        <category>机器学习</category>
        
      </item>
    
      <item>
        <title>你好，旅行者～</title>
        <description>&lt;p&gt;原本打算把之前进行的论文阅读报告记录一下，然而由于&lt;strong&gt;不可抗力&lt;/strong&gt;的原因，最终在github上搭了个博客来完成原来的目标。总之，尽量保持更新。&lt;/p&gt;
</description>
        <pubDate>Tue, 12 May 2015 00:00:00 +0800</pubDate>
        <link>http://haowai31.github.io//blog/2015/05/12/hello.html</link>
        <guid isPermaLink="true">http://haowai31.github.io//blog/2015/05/12/hello.html</guid>
        
        <category>开始</category>
        
      </item>
    
  </channel>
</rss>
